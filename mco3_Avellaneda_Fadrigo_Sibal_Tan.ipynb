{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f514d40-2aaa-4c1d-853b-58364ac05f3a",
   "metadata": {},
   "source": [
    "# mco3_Avellaneda_Fadrigo_Sibal_Tan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. Overview of Project\n",
    "2. Description and crediting of Dataset\n",
    "3. Data Preprocessing\n",
    "4. Definition of Classification Task\n",
    "    - Explain what will be classified\n",
    "    - Give features and labels for ML task\n",
    "    - Rationale and relevance of dataset and classification\n",
    "5. Implementation and Evaluation of Classification Models\n",
    "    - List and describe models to be used\n",
    "    - ML code proper, with appropriate explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### PLACEHOLDER TEXT:\n",
    ">Project aims to implement and compare the performance of 2 ML models for a classification task of their choice. An applicable dataset was chosen and was used on the 2 ML models. A deeper-than-surface-level understanding of the ML model in the context of the dataset is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This [dataset](https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs), entitled \"30000 Spotify Songs\" was uploaded by [Joakin Arvidsson](https://www.kaggle.com/joebeachcapital) on [Kaggle](https://www.kaggle.com/). Additionally the dataset was locally downloaded and can be found in \"\\Spotify Dataset\".\n",
    "\n",
    "The dataset contains about 30,000 songs of varying genres from the Spotify API using the spotifyr package (details listed in readme in \"\\Spotify Dataset\"). It contains information like the unique track ID, release date, genre, etc. \n",
    "\n",
    "The dataset has 23 columns they are as follows:\n",
    "1.  track_id: Song unique ID\n",
    "2.  track_name: Song name\n",
    "3.  track_artist: Song artist\n",
    "4.  track_popularity: Song popularity where higher is better\n",
    "5.  track_album_id: Album unique ID\n",
    "6.  track_album_name: Song album name\n",
    "7.  track_album_release_date: Date when album released\n",
    "8.  playlist_name: Name of playlist\n",
    "9.  playlist_id: Playlist ID\n",
    "10. playlist_genre: Playlist genre\n",
    "11. playlist_subgenre: Playlist subgenre\n",
    "12. danceability: Describes how suitable a track is for dancing based on different factors like tempo, rhythm stability, etc. 0.0 denotes least dancable and 1.0 denotes most dancable.\n",
    "13. energy: Measured from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. \n",
    "14. key: The estimated overall key of the track.\n",
    "15. loudness: The overall loudness of a track in decibels (dB). Typically range from -60 to 0 dB.\n",
    "16. mode: Mode indicates the modality (major or minor) of a track. 1 represents Major and 0 represents Minor\n",
    "17. speechiness: Detects the presence of spoken words in a track. Values close to 1.0 likely indicate a talk show or podcast. Values above 0.66 means that tracks are probably made entirely of spoken words. 0.33 to 0.66 means that the track may have both music and speech. Values below 0.33 represent music or non-speech tracks. \n",
    "18. acousticness: Confidence measure from 0.0 to 1.0 whether the track is acoustic. A higher value means a higher confidence. \n",
    "19. instrumentalness: Predicts whether a track contains no vocals. Values above 0.5 intend to represent musical tracks, with the values approching 1.0 denote a higher degree of confidence.\n",
    "20. liveness: Detects the presence of an audience in the recording. Values above 0.8 indicate that a track likely recorded live.\n",
    "21. valence: Measured from 0.0 to 1.0 describing the musical positiveness conveyed by a track. \n",
    "22. tempo: The overall estimated tempo of a track in beats per minute (BPM). \n",
    "23. duration_ms: Duration of song in milliseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries of preprocessing and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# keep plt inline in ntbk instead of new window\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset for visualization and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../MCO3-MachineLearning/Spotify_Dataset/spotify_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and remove rows if there are null cells in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows, _ = list(np.where(pd.isnull(df)))\n",
    "nan_rows = nan_rows.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nan_rows:\n",
    "    nan_rows = list(set(nan_rows))\n",
    "    nan_rows.sort()\n",
    "    print(nan_rows)\n",
    "else:\n",
    "    print(\"No NaN values in df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Classification Task\n",
    "- Spotify - release date, any label after subgenre\n",
    "- Malware - Malware vs Goodware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Implementation and Evaluation\n",
    "\n",
    "Candidate models (all present in SKLearn):\n",
    "- Logistic Regression\n",
    "- SVC/NuSVC\n",
    "- SGDClassifier - \"Stochastic Gradient Descent\"\n",
    "- Decision Tree Classifier\n",
    "- MLP Classifier - \"Multi-Level Perceptron\"\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting Classifier\n",
    "- Ada Boost Classifier\n",
    "- KNeighbors Classifier\n",
    "- Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
